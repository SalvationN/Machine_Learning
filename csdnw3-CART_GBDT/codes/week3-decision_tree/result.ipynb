{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 再一次调整n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一步的关键是调小学习率，增大弱学习器的数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              test-mlogloss-mean  test-mlogloss-std  train-mlogloss-mean  \\\n",
      "n_estimators                                                               \n",
      "0                       1.086267           0.000037             1.086127   \n",
      "1                       1.074347           0.000081             1.074061   \n",
      "2                       1.062829           0.000123             1.062397   \n",
      "3                       1.051686           0.000147             1.051115   \n",
      "4                       1.040902           0.000182             1.040195   \n",
      "5                       1.030468           0.000214             1.029624   \n",
      "6                       1.020357           0.000239             1.019382   \n",
      "7                       1.010586           0.000269             1.009476   \n",
      "8                       1.001116           0.000312             0.999870   \n",
      "9                       0.991938           0.000335             0.990553   \n",
      "10                      0.983036           0.000368             0.981522   \n",
      "11                      0.974415           0.000397             0.972761   \n",
      "12                      0.966025           0.000422             0.964249   \n",
      "13                      0.957891           0.000423             0.955987   \n",
      "14                      0.949997           0.000454             0.947966   \n",
      "15                      0.942335           0.000502             0.940177   \n",
      "16                      0.934872           0.000516             0.932596   \n",
      "17                      0.927650           0.000528             0.925244   \n",
      "18                      0.920626           0.000547             0.918098   \n",
      "19                      0.913786           0.000557             0.911130   \n",
      "20                      0.907155           0.000581             0.904385   \n",
      "21                      0.900697           0.000575             0.897807   \n",
      "22                      0.894417           0.000578             0.891405   \n",
      "23                      0.888322           0.000562             0.885179   \n",
      "24                      0.882359           0.000560             0.879109   \n",
      "25                      0.876587           0.000542             0.873208   \n",
      "26                      0.870947           0.000546             0.867449   \n",
      "27                      0.865455           0.000524             0.861846   \n",
      "28                      0.860103           0.000516             0.856394   \n",
      "29                      0.854892           0.000509             0.851063   \n",
      "...                          ...                ...                  ...   \n",
      "1580                    0.586514           0.002732             0.482166   \n",
      "1581                    0.586517           0.002731             0.482105   \n",
      "1582                    0.586512           0.002728             0.482071   \n",
      "1583                    0.586510           0.002721             0.482024   \n",
      "1584                    0.586506           0.002728             0.481959   \n",
      "1585                    0.586499           0.002730             0.481913   \n",
      "1586                    0.586502           0.002735             0.481866   \n",
      "1587                    0.586503           0.002739             0.481818   \n",
      "1588                    0.586495           0.002738             0.481766   \n",
      "1589                    0.586495           0.002732             0.481713   \n",
      "1590                    0.586489           0.002734             0.481654   \n",
      "1591                    0.586487           0.002737             0.481586   \n",
      "1592                    0.586490           0.002735             0.481536   \n",
      "1593                    0.586488           0.002734             0.481498   \n",
      "1594                    0.586488           0.002741             0.481457   \n",
      "1595                    0.586489           0.002744             0.481422   \n",
      "1596                    0.586489           0.002745             0.481362   \n",
      "1597                    0.586487           0.002742             0.481317   \n",
      "1598                    0.586473           0.002738             0.481244   \n",
      "1599                    0.586471           0.002739             0.481199   \n",
      "1600                    0.586466           0.002738             0.481153   \n",
      "1601                    0.586465           0.002745             0.481092   \n",
      "1602                    0.586458           0.002744             0.481028   \n",
      "1603                    0.586453           0.002756             0.480983   \n",
      "1604                    0.586446           0.002748             0.480923   \n",
      "1605                    0.586439           0.002756             0.480846   \n",
      "1606                    0.586436           0.002761             0.480806   \n",
      "1607                    0.586442           0.002767             0.480764   \n",
      "1608                    0.586437           0.002764             0.480710   \n",
      "1609                    0.586428           0.002765             0.480643   \n",
      "\n",
      "              train-mlogloss-std  \n",
      "n_estimators                      \n",
      "0                       0.000035  \n",
      "1                       0.000066  \n",
      "2                       0.000096  \n",
      "3                       0.000132  \n",
      "4                       0.000161  \n",
      "5                       0.000189  \n",
      "6                       0.000221  \n",
      "7                       0.000240  \n",
      "8                       0.000259  \n",
      "9                       0.000292  \n",
      "10                      0.000311  \n",
      "11                      0.000335  \n",
      "12                      0.000359  \n",
      "13                      0.000395  \n",
      "14                      0.000409  \n",
      "15                      0.000415  \n",
      "16                      0.000437  \n",
      "17                      0.000456  \n",
      "18                      0.000479  \n",
      "19                      0.000514  \n",
      "20                      0.000524  \n",
      "21                      0.000560  \n",
      "22                      0.000594  \n",
      "23                      0.000627  \n",
      "24                      0.000663  \n",
      "25                      0.000704  \n",
      "26                      0.000726  \n",
      "27                      0.000765  \n",
      "28                      0.000808  \n",
      "29                      0.000839  \n",
      "...                          ...  \n",
      "1580                    0.000291  \n",
      "1581                    0.000288  \n",
      "1582                    0.000288  \n",
      "1583                    0.000306  \n",
      "1584                    0.000311  \n",
      "1585                    0.000317  \n",
      "1586                    0.000343  \n",
      "1587                    0.000333  \n",
      "1588                    0.000341  \n",
      "1589                    0.000334  \n",
      "1590                    0.000341  \n",
      "1591                    0.000348  \n",
      "1592                    0.000346  \n",
      "1593                    0.000334  \n",
      "1594                    0.000326  \n",
      "1595                    0.000319  \n",
      "1596                    0.000330  \n",
      "1597                    0.000328  \n",
      "1598                    0.000326  \n",
      "1599                    0.000335  \n",
      "1600                    0.000330  \n",
      "1601                    0.000327  \n",
      "1602                    0.000309  \n",
      "1603                    0.000305  \n",
      "1604                    0.000310  \n",
      "1605                    0.000299  \n",
      "1606                    0.000305  \n",
      "1607                    0.000293  \n",
      "1608                    0.000293  \n",
      "1609                    0.000286  \n",
      "\n",
      "[1610 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "path = 'Desktop/RentListingInquries/code/data/'\n",
    "test = pd.read_csv(path+'RentListingInquries_FE_test.csv')\n",
    "train = pd.read_csv(path+'RentListingInquries_FE_train.csv')\n",
    "\n",
    "y_train = train['interest_level']\n",
    "x_train = train.drop('interest_level',axis=1)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=3)\n",
    "def modelfit(alg, X_train, y_train, cv_folds=None, early_stopping_rounds=10):\n",
    "    xgb_param = alg.get_xgb_params()\n",
    "    xgb_param['num_class'] = 3       #因为是三类分类问题\n",
    "    \n",
    "    xgtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "        \n",
    "    cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], folds =cv_folds,\n",
    "             metrics='mlogloss', early_stopping_rounds=early_stopping_rounds)\n",
    "    #直接采用xgb的cv函数\n",
    "    \n",
    "    cvresult.to_csv('2_nestimators.csv', index_label = 'n_estimators')\n",
    "    n_estimators = cvresult.shape[0]\n",
    "    alg.set_params(n_estimators = n_estimators)\n",
    "    alg.fit(X_train, y_train, eval_metric='mlogloss')\n",
    "    \n",
    "xgb4 = XGBClassifier(\n",
    "        learning_rate = 0.02,\n",
    "        n_estimators=1800,      #将leaning_rate调小，再增大n_estimators\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma = 0,\n",
    "        objective='multi:softprob',\n",
    "        seed=3\n",
    ")\n",
    "modelfit(xgb4,x_train,y_train,cv_folds=kfold)\n",
    "cvresult = pd.DataFrame.from_csv('2_nestimators.csv')\n",
    "print(cvresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'gamma': 0,\n",
       " 'learning_rate': 0.02,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 1610,\n",
       " 'nthread': 1,\n",
       " 'objective': 'multi:softprob',\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'seed': 3,\n",
       " 'silent': 1,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb4.get_xgb_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找到最佳参数为1610"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存模型，并进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>price</th>\n",
       "      <th>price_bathrooms</th>\n",
       "      <th>price_bedrooms</th>\n",
       "      <th>room_diff</th>\n",
       "      <th>room_num</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>...</th>\n",
       "      <th>virtual</th>\n",
       "      <th>walk</th>\n",
       "      <th>walls</th>\n",
       "      <th>war</th>\n",
       "      <th>washer</th>\n",
       "      <th>water</th>\n",
       "      <th>wheelchair</th>\n",
       "      <th>wifi</th>\n",
       "      <th>windows</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2950</td>\n",
       "      <td>1475.000000</td>\n",
       "      <td>1475.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2850</td>\n",
       "      <td>1425.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3758</td>\n",
       "      <td>1879.000000</td>\n",
       "      <td>1879.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3300</td>\n",
       "      <td>1650.000000</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4900</td>\n",
       "      <td>1633.333333</td>\n",
       "      <td>1633.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bathrooms  bedrooms  price  price_bathrooms  price_bedrooms  room_diff  \\\n",
       "0        1.0         1   2950      1475.000000     1475.000000        0.0   \n",
       "1        1.0         2   2850      1425.000000      950.000000       -1.0   \n",
       "2        1.0         1   3758      1879.000000     1879.000000        0.0   \n",
       "3        1.0         2   3300      1650.000000     1100.000000       -1.0   \n",
       "4        2.0         2   4900      1633.333333     1633.333333        0.0   \n",
       "\n",
       "   room_num  Year  Month  Day  ...   virtual  walk  walls  war  washer  water  \\\n",
       "0       2.0  2016      6   11  ...         0     0      0    0       0      0   \n",
       "1       3.0  2016      6   24  ...         0     0      0    1       0      0   \n",
       "2       2.0  2016      6    3  ...         0     0      0    0       0      0   \n",
       "3       3.0  2016      6   11  ...         0     0      0    0       0      0   \n",
       "4       4.0  2016      4   12  ...         0     0      0    1       0      0   \n",
       "\n",
       "   wheelchair  wifi  windows  work  \n",
       "0           0     0        0     0  \n",
       "1           0     0        0     0  \n",
       "2           0     0        0     0  \n",
       "3           1     0        0     0  \n",
       "4           0     0        0     0  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(xgb4.predict_proba(test))\n",
    "y_pred.columns = [\"high\", \"medium\", \"low\"]\n",
    "y_pred.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           high    medium       low\n",
      "0      0.094963  0.376525  0.528511\n",
      "1      0.250027  0.423065  0.326908\n",
      "2      0.051716  0.109980  0.838304\n",
      "3      0.049186  0.342774  0.608040\n",
      "4      0.071391  0.247828  0.680780\n",
      "5      0.003263  0.099394  0.897344\n",
      "6      0.023500  0.305606  0.670894\n",
      "7      0.118151  0.533122  0.348728\n",
      "8      0.083946  0.456714  0.459340\n",
      "9      0.062358  0.275904  0.661738\n",
      "10     0.004559  0.041413  0.954027\n",
      "11     0.049609  0.466949  0.483442\n",
      "12     0.067255  0.384020  0.548725\n",
      "13     0.008663  0.035522  0.955815\n",
      "14     0.008356  0.065403  0.926241\n",
      "15     0.011502  0.115606  0.872892\n",
      "16     0.090720  0.394696  0.514583\n",
      "17     0.000318  0.007151  0.992531\n",
      "18     0.007926  0.077327  0.914747\n",
      "19     0.113369  0.471466  0.415165\n",
      "20     0.034955  0.256890  0.708156\n",
      "21     0.015509  0.165372  0.819119\n",
      "22     0.086026  0.344184  0.569790\n",
      "23     0.281905  0.490924  0.227171\n",
      "24     0.007416  0.180890  0.811694\n",
      "25     0.178922  0.550274  0.270803\n",
      "26     0.013526  0.182144  0.804330\n",
      "27     0.307473  0.344630  0.347898\n",
      "28     0.050468  0.472429  0.477103\n",
      "29     0.131349  0.265566  0.603084\n",
      "...         ...       ...       ...\n",
      "74629  0.107362  0.518584  0.374055\n",
      "74630  0.078986  0.544411  0.376602\n",
      "74631  0.080900  0.324172  0.594928\n",
      "74632  0.010127  0.132559  0.857314\n",
      "74633  0.007413  0.183300  0.809287\n",
      "74634  0.002992  0.043138  0.953870\n",
      "74635  0.079263  0.238076  0.682662\n",
      "74636  0.000819  0.027599  0.971582\n",
      "74637  0.104396  0.371201  0.524403\n",
      "74638  0.024170  0.105013  0.870817\n",
      "74639  0.002041  0.032073  0.965885\n",
      "74640  0.003714  0.027777  0.968509\n",
      "74641  0.127912  0.432344  0.439744\n",
      "74642  0.039527  0.239126  0.721347\n",
      "74643  0.017911  0.272542  0.709548\n",
      "74644  0.001751  0.091366  0.906884\n",
      "74645  0.358641  0.470696  0.170663\n",
      "74646  0.017502  0.116056  0.866442\n",
      "74647  0.065435  0.280623  0.653942\n",
      "74648  0.091529  0.459046  0.449425\n",
      "74649  0.246964  0.526378  0.226658\n",
      "74650  0.419270  0.448624  0.132106\n",
      "74651  0.001354  0.080932  0.917714\n",
      "74652  0.026112  0.100717  0.873171\n",
      "74653  0.000572  0.019658  0.979770\n",
      "74654  0.038119  0.160415  0.801466\n",
      "74655  0.001768  0.015183  0.983050\n",
      "74656  0.079214  0.343469  0.577317\n",
      "74657  0.489694  0.405015  0.105291\n",
      "74658  0.052806  0.357617  0.589577\n",
      "\n",
      "[74659 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
